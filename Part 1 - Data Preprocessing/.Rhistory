swirl()
library(swirl)
swirl()
5 +7
ls()
install.packages("networkD3")
library("networkD3")
src <- c("A", "A", "A", "A",
"B", "B", "C", "C", "D")
target <- c("B", "C", "D", "J",
"E", "F", "G", "H", "I")
target
simpleNetwork(networkData)
networkData <- data.frame(src, target)
networkData
simpleNetwork(networkData)
library("d3Network")
install.packages("d3Network")
library("d3Network")
library("RSiteCatalyst")
SCAuth("p.singh:FCA EMEA", "77491d458a82880b097ad54b283acbd6")
pathpattern <- c("::anything::", "::anything::")
next_page <- QueuePathing("fcae.fiat.belux",
"2016-01-01",
"2016-08-31",
metric="pageviews",
element="page",
pathpattern,
top = 50000)
rm(list = ls())
library("d3Network")
install.packages("d3Network")
library("d3Network")
library("RSiteCatalyst")
SCAuth("p.singh:FCA EMEA", "77491d458a82880b097ad54b283acbd6")
pathpattern <- c("::anything::", "::anything::")
next_page <- QueuePathing("fcae.fiat.belux",
"2016-01-01",
"2016-08-31",
metric="pageviews",
element="page",
pathpattern,
top = 50000)
rm(list = ls())
install.packages(c("curl", "httr"))
install.packages(c("curl", "httr"))
#Multi-page pathing
library("d3Network")
library("RSiteCatalyst")
#### Authentication
#SCAuth("name", "secret")
SCAuth("p.singh:FCA EMEA", "77491d458a82880b097ad54b283acbd6")
#### Get All Possible Paths with ("::anything::", "::anything::")
pathpattern <- c("::anything::", "::anything::")
next_page <- QueuePathing("fcae.fiat.belux",
"2016-01-01",
"2016-08-31",
metric="pageviews",
element="page",
pathpattern,
top = 50000)
#Optional step: Cleaning my pagename URLs to remove to domain for clarity
next_page$step.1 <- sub("www.fiat.be/fr/","",
next_page$step.1, ignore.case = TRUE)
next_page$step.2 <- sub("www.fiat.be/fr/","",
next_page$step.2, ignore.case = TRUE)
#Filter out Entered Site and duplicate rows, >120 for chart legibility
links <- subset(next_page, count >= 120 & step.1 != "Entered Site")
#Get unique values of page name to create nodes df
#Create an index value, starting at 0
nodes <- as.data.frame(unique(c(links$step.1, links$step.2)))
names(nodes) <- "name"
nodes$nodevalue <- as.numeric(row.names(nodes)) - 1
#Convert string to numeric nodeid
links <- merge(links, nodes, by.x="step.1", by.y="name")
names(links) <- c("step.1", "step.2", "value", "segment.id", "segment.name", "source")
links <- merge(links, nodes, by.x="step.2", by.y="name")
names(links) <- c("step.2", "step.1", "value", "segment.id", "segment.name","source", "target")
#Create next page Sankey chart
d3output = "all.html"
d3Sankey(Links = links, Nodes = nodes, Source = "source",
Target = "target", Value = "value", NodeID = "name",
fontsize = 12, nodeWidth = 50, file = d3output, width = 750, height = 700)
d3output
d3Sankey(Links = links, Nodes = nodes, Source = "source",
Target = "target", Value = "value", NodeID = "name",
fontsize = 12, nodeWidth = 50, file = d3output, width = 750, height = 700)
cwd()
getcwd()
getwd()
rm(list = ls())
URL <- paste0(
"https://cdn.rawgit.com/christophergandrud/networkD3/",
"master/JSONdata/energy.json")
Energy <- jsonlite::fromJSON(URL)
sankeyNetwork(Links = Energy$links, Nodes = Energy$nodes, Source = "source",
Target = "target", Value = "value", NodeID = "name",
units = "TWh", fontSize = 12, nodeWidth = 30)
sankeyNetwork(Links = Energy$links, Nodes = Energy$nodes, Source = "source", Target = "target", Value = "value", NodeID = "name", units = "TWh", fontSize = 12, nodeWidth = 30)
library(d3Network)
sankeyNetwork(Links = Energy$links, Nodes = Energy$nodes, Source = "source", Target = "target", Value = "value", NodeID = "name", units = "TWh", fontSize = 12, nodeWidth = 30)
library(networkD3)
sankeyNetwork(Links = Energy$links, Nodes = Energy$nodes, Source = "source", Target = "target", Value = "value", NodeID = "name", units = "TWh", fontSize = 12, nodeWidth = 30)
Energy$links[:2]
Energy$links[,2]
Energy$nodes
URL
URL = file:///C:/Users/sainath.gaddam/Desktop/Pranab/data.json
URL = "file:///C:/Users/sainath.gaddam/Desktop/Pranab/data.json"
Energy <- jsonlite::fromJSON(URL)
install.packages("RJSONIO")
library("RJSONIO")
l <- fromJSON({"nodes":[
{"name":"Agricultural 'waste'"},
{"name":"Bio-conversion"}
],
"links":[
{"source":0,"target":1,"value":124.729},
{"source":1,"target":2,"value":0.597}
]})
rm(list = ls())
#Multi-page pathing
library("d3Network")
library("RSiteCatalyst")
#### Authentication
#SCAuth("name", "secret")
SCAuth("p.singh:FCA EMEA", "77491d458a82880b097ad54b283acbd6")
#### Get All Possible Paths with ("::anything::", "::anything::")
pathpattern <- c("::anything::", "::anything::")
next_page <- QueuePathing("fcae.fiat.belux",
"2016-01-01",
"2016-08-31",
metric="pageviews",
element="page",
pathpattern,
top = 50000)
#Optional step: Cleaning my pagename URLs to remove to domain for clarity
next_page$step.1 <- sub("www.fiat.be/fr/","",
next_page$step.1, ignore.case = TRUE)
next_page$step.2 <- sub("www.fiat.be/fr/","",
next_page$step.2, ignore.case = TRUE)
#Filter out Entered Site and duplicate rows, >120 for chart legibility
links <- subset(next_page, count >= 120 & step.1 != "Entered Site")
#Get unique values of page name to create nodes df
#Create an index value, starting at 0
nodes <- as.data.frame(unique(c(links$step.1, links$step.2)))
names(nodes) <- "name"
nodes$nodevalue <- as.numeric(row.names(nodes)) - 1
#Convert string to numeric nodeid
links <- merge(links, nodes, by.x="step.1", by.y="name")
names(links) <- c("step.1", "step.2", "value", "segment.id", "segment.name", "source")
links <- merge(links, nodes, by.x="step.2", by.y="name")
names(links) <- c("step.2", "step.1", "value", "segment.id", "segment.name","source", "target")
#Create next page Sankey chart
d3output = "all.html"
d3Sankey(Links = links, Nodes = nodes, Source = "source",
Target = "target", Value = "value", NodeID = "name",
fontsize = 12, nodeWidth = 50, file = d3output, width = 750, height = 700)
rm(list = ls())
str(state.region)
head(state.region)
state.region
names(state.region)
str(state.region)
table(state.region)
barplot(table(state.region))
barplot(table(state.region), cex.names = 0.5)
barplot(prop.table(table(state.region)), cex.names = 0.5)
barplot(table(state.region), cex.names = 0.5)
barplot(prop.table(table(state.region)), cex.names = 0.5)
barplot(table(state.region), cex.names = 0.5)
barplot(prop.table(table(state.region)), cex.names = 0.5)
?par
x <- 5:9
x
y <- (x < 7)
y
x <- c(3,7,NA)
y <- c(NA,1,a)
y <- c(NA,1,2)
x+y
sum(x)
sum(x, na.rm = TRUE)
is.na(x)
x[is.na(x)]
x[!is.na(x)]
version
mod <- lm(dist ~ speed, data = cars)
mean(mod$residuals)
par(mfrow = c(2,2))
mod_1 <- lm(mpg ~ disp, data = mtcars)
plot(mod_1)
library(swirl)
swirl()
swirl()
library(car)
mod2 <- lm(mpg ~ ., data = mtcars)
vif(mod2)
summary(mod2)
library(carrplot)
install.packages(carrplot)
install.packages("corrplot")
library(carrplot)
library(corrplot)
cor(mtcars[,-1])
corrplot(cor(mtcars[,-1]))
mod <- lm(mpg ~ cyl + gear, data = mtcars)
summary(mod)
vif(mod = )
vif(mod)
par(mfrow=c(2,2))
mod <- lm(dist ~ speed, data = cars)
plot(mod)
install.packages("gvlma")
library(gvlma)
gvlma::gvlma(mod)
mod <- lm(dist ~ speed, data=cars[-c(23, 35, 49), ])
gvlma::gvlma(mod)
rm(list=ls(all=TRUE)) #clear all objects in workspace
install.packages("RGoogleAnalytics")
install.packages("httpuv")
install.packages("Rcpp")
install.packages("RCurl")
library("Rcpp")
library(XLConnect);
library(RGoogleAnalytics)
require(httpuv)
St_date='2017-01-01'
En_date='2017-06-05'
client.id <- "374177728354-lukeb737s4smlcsmdf52ninn90ce0t9d.apps.googleusercontent.com"
client.secret <- "EHgTYZ-ZYGEpPbj1gGAcTi0V"
token <- Auth(client.id,client.secret)
token <- Auth(client.id,client.secret)
token <- Auth(client.id,client.secret)
token <- Auth(client.id,client.secret)
rm(list=ls(all=TRUE)) #clear all objects in workspace
library("Rcpp")
library(XLConnect);
library(RGoogleAnalytics)
require(httpuv)
St_date='2017-01-01'
En_date='2017-06-05'
client.id <- "374177728354-lukeb737s4smlcsmdf52ninn90ce0t9d.apps.googleusercontent.com"
client.secret <- "EHgTYZ-ZYGEpPbj1gGAcTi0V"
token <- Auth(client.id,client.secret)
save(token,file="./token_file")
load("./token_file")
token
ValidateToken(token)
Profile <- c( "ga:97753012")
starttime=Sys.time()
query.list <- Init(start.date = as.character(St_date),
end.date = as.character(En_date),
dimensions = "ga:yearMonth, ga:week,ga:channelGrouping, ga:landingPagePath, ga:pageDepth,  ga:deviceCategory",
metrics = "ga:users, ga:sessions, ga:bounceRate, ga:pageviews, ga:avgSessionDuration, ga:totalEvents, ga:goalStartsAll, ga:goal1Starts, ga:goal3Starts, ga:goal6Starts",
start.index = 1,
max.results = 10000,
filters = c("ga:userType==New Visitor"),
#sort = "-ga:transactions",
table.id = PID)
ga.query <- QueryBuilder(query.list)
query.list <- Init(start.date = as.character(St_date),
end.date = as.character(En_date),
dimensions = "ga:yearMonth, ga:week,ga:channelGrouping, ga:landingPagePath, ga:pageDepth,  ga:deviceCategory",
metrics = "ga:users, ga:sessions, ga:bounceRate, ga:pageviews, ga:avgSessionDuration, ga:totalEvents, ga:goalStartsAll, ga:goal1Starts, ga:goal3Starts, ga:goal6Starts",
start.index = 1,
max.results = 10000,
filters = c("ga:userType==New Visitor"),
#sort = "-ga:transactions",
table.id = PID)
for(i in 1:length(Profile)){
flag <- TRUE
PID=Profile[i]
PID
ValidateToken(token)
query.list <- Init(start.date = as.character(St_date),
end.date = as.character(En_date),
dimensions = "ga:yearMonth, ga:week,ga:channelGrouping, ga:landingPagePath, ga:pageDepth,  ga:deviceCategory",
metrics = "ga:users, ga:sessions, ga:bounceRate, ga:pageviews, ga:avgSessionDuration, ga:totalEvents, ga:goalStartsAll, ga:goal1Starts, ga:goal3Starts, ga:goal6Starts",
start.index = 1,
max.results = 10000,
filters = c("ga:userType==New Visitor"),
#sort = "-ga:transactions",
table.id = PID)
ga.query <- QueryBuilder(query.list)
# Extract the data and store it in a data-frame
tryCatch ( ga.dataCount <- nrow(GetReportData(ga.query, token)), error=function(e) flag<<-FALSE)
if (!flag) next
if (ga.dataCount < 10000)     {
# Extract the data and store it in a data-frame
ga.data <- GetReportData(ga.query, token)
} else {
# Extract the data and store it in a data-frame
ga.data <- GetReportData(ga.query, token, paginate_query=TRUE)
}
endtime=Sys.time()
ga.data$PID <- PID
print(PID)
ga.Consolidated <- rbind(ga.Consolidated, ga.data)
}
for(i in 1:length(Profile)){
flag <- TRUE
PID=Profile[i]
PID
ValidateToken(token)
query.list <- Init(start.date = as.character(St_date),
end.date = as.character(En_date),
dimensions = "ga:yearMonth, ga:week,ga:channelGrouping, ga:landingPagePath, ga:pageDepth,  ga:deviceCategory",
metrics = "ga:users, ga:sessions, ga:bounceRate, ga:pageviews, ga:avgSessionDuration, ga:totalEvents, ga:goalStartsAll, ga:goal1Starts, ga:goal3Starts, ga:goal6Starts",
start.index = 1,
max.results = 10000,
#filters = c("ga:userType==New Visitor"),
#sort = "-ga:transactions",
table.id = PID)
ga.query <- QueryBuilder(query.list)
# Extract the data and store it in a data-frame
tryCatch ( ga.dataCount <- nrow(GetReportData(ga.query, token)), error=function(e) flag<<-FALSE)
if (!flag) next
if (ga.dataCount < 10000)     {
# Extract the data and store it in a data-frame
ga.data <- GetReportData(ga.query, token)
} else {
# Extract the data and store it in a data-frame
ga.data <- GetReportData(ga.query, token, paginate_query=TRUE)
}
endtime=Sys.time()
ga.data$PID <- PID
print(PID)
ga.Consolidated <- rbind(ga.Consolidated, ga.data)
}
for(i in 1:length(Profile)){
flag <- TRUE
PID=Profile[i]
PID
ValidateToken(token)
query.list <- Init(start.date = as.character(St_date),
end.date = as.character(En_date),
dimensions = "ga:yearMonth, ga:week,ga:channelGrouping, ga:landingPagePath, ga:pageDepth,  ga:deviceCategory",
metrics = "ga:users, ga:sessions, ga:bounceRate, ga:pageviews, ga:avgSessionDuration, ga:totalEvents, ga:goalStartsAll, ga:goal1Starts, ga:goal3Starts, ga:goal6Starts",
start.index = 1,
max.results = 10000,
filters = "ga:userType%3D%3DNew Visitor",
#sort = "-ga:transactions",
table.id = PID)
ga.query <- QueryBuilder(query.list)
# Extract the data and store it in a data-frame
tryCatch ( ga.dataCount <- nrow(GetReportData(ga.query, token)), error=function(e) flag<<-FALSE)
if (!flag) next
if (ga.dataCount < 10000)     {
# Extract the data and store it in a data-frame
ga.data <- GetReportData(ga.query, token)
} else {
# Extract the data and store it in a data-frame
ga.data <- GetReportData(ga.query, token, paginate_query=TRUE)
}
endtime=Sys.time()
ga.data$PID <- PID
print(PID)
ga.Consolidated <- rbind(ga.Consolidated, ga.data)
}
for(i in 1:length(Profile)){
flag <- TRUE
PID=Profile[i]
PID
ValidateToken(token)
query.list <- Init(start.date = as.character(St_date),
end.date = as.character(En_date),
dimensions = "ga:yearMonth, ga:week,ga:channelGrouping, ga:landingPagePath, ga:pageDepth,  ga:deviceCategory",
metrics = "ga:users, ga:sessions, ga:bounceRate, ga:pageviews, ga:avgSessionDuration, ga:totalEvents, ga:goalStartsAll, ga:goal1Starts, ga:goal3Starts, ga:goal6Starts",
start.index = 1,
segment = "ga:userType==New%20Visitor",
max.results = 10000,
#filters = "ga:userType%3D%3DNew Visitor",
#sort = "-ga:transactions",
table.id = PID)
ga.query <- QueryBuilder(query.list)
# Extract the data and store it in a data-frame
tryCatch ( ga.dataCount <- nrow(GetReportData(ga.query, token)), error=function(e) flag<<-FALSE)
if (!flag) next
if (ga.dataCount < 10000)     {
# Extract the data and store it in a data-frame
ga.data <- GetReportData(ga.query, token)
} else {
# Extract the data and store it in a data-frame
ga.data <- GetReportData(ga.query, token, paginate_query=TRUE)
}
endtime=Sys.time()
ga.data$PID <- PID
print(PID)
ga.Consolidated <- rbind(ga.Consolidated, ga.data)
}
for(i in 1:length(Profile)){
flag <- TRUE
PID=Profile[i]
PID
ValidateToken(token)
query.list <- Init(start.date = as.character(St_date),
end.date = as.character(En_date),
dimensions = "ga:yearMonth, ga:week,ga:channelGrouping, ga:landingPagePath, ga:pageDepth,  ga:deviceCategory",
metrics = "ga:users, ga:sessions, ga:bounceRate, ga:pageviews, ga:avgSessionDuration, ga:totalEvents, ga:goalStartsAll, ga:goal1Starts, ga:goal3Starts, ga:goal6Starts",
start.index = 1,
#segment = "ga:userType==New%20Visitor",
max.results = 10000,
#filters = "ga:userType==New%20Visitor",
#sort = "-ga:transactions",
table.id = PID)
ga.query <- QueryBuilder(query.list)
# Extract the data and store it in a data-frame
tryCatch ( ga.dataCount <- nrow(GetReportData(ga.query, token)), error=function(e) flag<<-FALSE)
if (!flag) next
if (ga.dataCount < 10000)     {
# Extract the data and store it in a data-frame
ga.data <- GetReportData(ga.query, token)
} else {
# Extract the data and store it in a data-frame
ga.data <- GetReportData(ga.query, token, paginate_query=TRUE)
}
endtime=Sys.time()
ga.data$PID <- PID
print(PID)
ga.Consolidated <- rbind(ga.Consolidated, ga.data)
}
for(i in 1:length(Profile)){
flag <- TRUE
PID=Profile[i]
PID
ValidateToken(token)
query.list <- Init(start.date = as.character(St_date),
end.date = as.character(En_date),
dimensions = "ga:yearMonth, ga:week,ga:channelGrouping, ga:landingPagePath, ga:pageDepth,  ga:deviceCategory",
metrics = "ga:users, ga:sessions, ga:bounceRate, ga:pageviews, ga:avgSessionDuration, ga:totalEvents, ga:goalStartsAll, ga:goal1Starts, ga:goal3Starts, ga:goal6Starts",
start.index = 1,
#segment = "ga:userType==New%20Visitor",
max.results = 10000,
filters = "ga:userType==New%20Visitor",
#sort = "-ga:transactions",
table.id = PID)
ga.query <- QueryBuilder(query.list)
# Extract the data and store it in a data-frame
tryCatch ( ga.dataCount <- nrow(GetReportData(ga.query, token)), error=function(e) flag<<-FALSE)
if (!flag) next
if (ga.dataCount < 10000)     {
# Extract the data and store it in a data-frame
ga.data <- GetReportData(ga.query, token)
} else {
# Extract the data and store it in a data-frame
ga.data <- GetReportData(ga.query, token, paginate_query=TRUE)
}
endtime=Sys.time()
ga.data$PID <- PID
print(PID)
ga.Consolidated <- rbind(ga.Consolidated, ga.data)
}
rm(list=ls(all=TRUE))
library("Rcpp")
library(XLConnect);
library(RGoogleAnalytics)
require(httpuv)
St_date='2017-01-01'
En_date='2017-06-05'
client.id <- "374177728354-lukeb737s4smlcsmdf52ninn90ce0t9d.apps.googleusercontent.com"
client.secret <- "EHgTYZ-ZYGEpPbj1gGAcTi0V"
token <- Auth(client.id,client.secret)
save(token,file="./token_file")
load("./token_file")
token
ValidateToken(token)
Profile <- c( "ga:97753012")
for(i in 1:length(Profile)){
flag <- TRUE
PID=Profile[i]
PID
ValidateToken(token)
query.list <- Init(start.date = as.character(St_date),
end.date = as.character(En_date),
dimensions = "ga:yearMonth, ga:week,ga:channelGrouping, ga:landingPagePath, ga:pageDepth,  ga:deviceCategory",
metrics = "ga:users, ga:sessions, ga:bounceRate, ga:pageviews, ga:avgSessionDuration, ga:totalEvents, ga:goalStartsAll, ga:goal1Starts, ga:goal3Starts, ga:goal6Starts",
start.index = 1,
#segment = "ga:userType==New%20Visitor",
max.results = 10000,
filters = "ga:userType==New%20Visitor",
#sort = "-ga:transactions",
table.id = PID)
ga.query <- QueryBuilder(query.list)
# Extract the data and store it in a data-frame
tryCatch ( ga.dataCount <- nrow(GetReportData(ga.query, token)), error=function(e) flag<<-FALSE)
if (!flag) next
if (ga.dataCount < 10000)     {
# Extract the data and store it in a data-frame
ga.data <- GetReportData(ga.query, token)
} else {
# Extract the data and store it in a data-frame
ga.data <- GetReportData(ga.query, token, paginate_query=TRUE)
}
endtime=Sys.time()
ga.data$PID <- PID
print(PID)
ga.Consolidated <- rbind(ga.Consolidated, ga.data)
}
dataset = read.csv("Data.csv")
setwd("C:/Users/sainath.gaddam/Desktop/Machine Learning A-Z/Part 1 - Data Preprocessing")
dataset = read.csv("Data.csv")
ave
ave?
?ave
dataset$Age = ifelse(is.na(dataset.Age), mean(dataset.Age, na.rm = TRUE),dataset$Age)
dataset$Age = ifelse(is.na(dataset$Age), mean(dataset$Age, na.rm = TRUE),dataset$Age)
View(dataset)
View(dataset)
dataset$Salary = ifelse(is.na(dataset$Salary), mean(dataset$Salary, na.rm = TRUE),dataset$Salary)
View(dataset)
View(dataset)
