x
y <- (x < 7)
y
x <- c(3,7,NA)
y <- c(NA,1,a)
y <- c(NA,1,2)
x+y
sum(x)
sum(x, na.rm = TRUE)
is.na(x)
x[is.na(x)]
x[!is.na(x)]
version
mod <- lm(dist ~ speed, data = cars)
mean(mod$residuals)
par(mfrow = c(2,2))
mod_1 <- lm(mpg ~ disp, data = mtcars)
plot(mod_1)
library(swirl)
swirl()
swirl()
library(car)
mod2 <- lm(mpg ~ ., data = mtcars)
vif(mod2)
summary(mod2)
library(carrplot)
install.packages(carrplot)
install.packages("corrplot")
library(carrplot)
library(corrplot)
cor(mtcars[,-1])
corrplot(cor(mtcars[,-1]))
mod <- lm(mpg ~ cyl + gear, data = mtcars)
summary(mod)
vif(mod = )
vif(mod)
par(mfrow=c(2,2))
mod <- lm(dist ~ speed, data = cars)
plot(mod)
install.packages("gvlma")
library(gvlma)
gvlma::gvlma(mod)
mod <- lm(dist ~ speed, data=cars[-c(23, 35, 49), ])
gvlma::gvlma(mod)
rm(list=ls(all=TRUE)) #clear all objects in workspace
install.packages("RGoogleAnalytics")
install.packages("httpuv")
install.packages("Rcpp")
install.packages("RCurl")
library("Rcpp")
library(XLConnect);
library(RGoogleAnalytics)
require(httpuv)
St_date='2017-01-01'
En_date='2017-06-05'
client.id <- "374177728354-lukeb737s4smlcsmdf52ninn90ce0t9d.apps.googleusercontent.com"
client.secret <- "EHgTYZ-ZYGEpPbj1gGAcTi0V"
token <- Auth(client.id,client.secret)
token <- Auth(client.id,client.secret)
token <- Auth(client.id,client.secret)
token <- Auth(client.id,client.secret)
rm(list=ls(all=TRUE)) #clear all objects in workspace
library("Rcpp")
library(XLConnect);
library(RGoogleAnalytics)
require(httpuv)
St_date='2017-01-01'
En_date='2017-06-05'
client.id <- "374177728354-lukeb737s4smlcsmdf52ninn90ce0t9d.apps.googleusercontent.com"
client.secret <- "EHgTYZ-ZYGEpPbj1gGAcTi0V"
token <- Auth(client.id,client.secret)
save(token,file="./token_file")
load("./token_file")
token
ValidateToken(token)
Profile <- c( "ga:97753012")
starttime=Sys.time()
query.list <- Init(start.date = as.character(St_date),
end.date = as.character(En_date),
dimensions = "ga:yearMonth, ga:week,ga:channelGrouping, ga:landingPagePath, ga:pageDepth,  ga:deviceCategory",
metrics = "ga:users, ga:sessions, ga:bounceRate, ga:pageviews, ga:avgSessionDuration, ga:totalEvents, ga:goalStartsAll, ga:goal1Starts, ga:goal3Starts, ga:goal6Starts",
start.index = 1,
max.results = 10000,
filters = c("ga:userType==New Visitor"),
#sort = "-ga:transactions",
table.id = PID)
ga.query <- QueryBuilder(query.list)
query.list <- Init(start.date = as.character(St_date),
end.date = as.character(En_date),
dimensions = "ga:yearMonth, ga:week,ga:channelGrouping, ga:landingPagePath, ga:pageDepth,  ga:deviceCategory",
metrics = "ga:users, ga:sessions, ga:bounceRate, ga:pageviews, ga:avgSessionDuration, ga:totalEvents, ga:goalStartsAll, ga:goal1Starts, ga:goal3Starts, ga:goal6Starts",
start.index = 1,
max.results = 10000,
filters = c("ga:userType==New Visitor"),
#sort = "-ga:transactions",
table.id = PID)
for(i in 1:length(Profile)){
flag <- TRUE
PID=Profile[i]
PID
ValidateToken(token)
query.list <- Init(start.date = as.character(St_date),
end.date = as.character(En_date),
dimensions = "ga:yearMonth, ga:week,ga:channelGrouping, ga:landingPagePath, ga:pageDepth,  ga:deviceCategory",
metrics = "ga:users, ga:sessions, ga:bounceRate, ga:pageviews, ga:avgSessionDuration, ga:totalEvents, ga:goalStartsAll, ga:goal1Starts, ga:goal3Starts, ga:goal6Starts",
start.index = 1,
max.results = 10000,
filters = c("ga:userType==New Visitor"),
#sort = "-ga:transactions",
table.id = PID)
ga.query <- QueryBuilder(query.list)
# Extract the data and store it in a data-frame
tryCatch ( ga.dataCount <- nrow(GetReportData(ga.query, token)), error=function(e) flag<<-FALSE)
if (!flag) next
if (ga.dataCount < 10000)     {
# Extract the data and store it in a data-frame
ga.data <- GetReportData(ga.query, token)
} else {
# Extract the data and store it in a data-frame
ga.data <- GetReportData(ga.query, token, paginate_query=TRUE)
}
endtime=Sys.time()
ga.data$PID <- PID
print(PID)
ga.Consolidated <- rbind(ga.Consolidated, ga.data)
}
for(i in 1:length(Profile)){
flag <- TRUE
PID=Profile[i]
PID
ValidateToken(token)
query.list <- Init(start.date = as.character(St_date),
end.date = as.character(En_date),
dimensions = "ga:yearMonth, ga:week,ga:channelGrouping, ga:landingPagePath, ga:pageDepth,  ga:deviceCategory",
metrics = "ga:users, ga:sessions, ga:bounceRate, ga:pageviews, ga:avgSessionDuration, ga:totalEvents, ga:goalStartsAll, ga:goal1Starts, ga:goal3Starts, ga:goal6Starts",
start.index = 1,
max.results = 10000,
#filters = c("ga:userType==New Visitor"),
#sort = "-ga:transactions",
table.id = PID)
ga.query <- QueryBuilder(query.list)
# Extract the data and store it in a data-frame
tryCatch ( ga.dataCount <- nrow(GetReportData(ga.query, token)), error=function(e) flag<<-FALSE)
if (!flag) next
if (ga.dataCount < 10000)     {
# Extract the data and store it in a data-frame
ga.data <- GetReportData(ga.query, token)
} else {
# Extract the data and store it in a data-frame
ga.data <- GetReportData(ga.query, token, paginate_query=TRUE)
}
endtime=Sys.time()
ga.data$PID <- PID
print(PID)
ga.Consolidated <- rbind(ga.Consolidated, ga.data)
}
for(i in 1:length(Profile)){
flag <- TRUE
PID=Profile[i]
PID
ValidateToken(token)
query.list <- Init(start.date = as.character(St_date),
end.date = as.character(En_date),
dimensions = "ga:yearMonth, ga:week,ga:channelGrouping, ga:landingPagePath, ga:pageDepth,  ga:deviceCategory",
metrics = "ga:users, ga:sessions, ga:bounceRate, ga:pageviews, ga:avgSessionDuration, ga:totalEvents, ga:goalStartsAll, ga:goal1Starts, ga:goal3Starts, ga:goal6Starts",
start.index = 1,
max.results = 10000,
filters = "ga:userType%3D%3DNew Visitor",
#sort = "-ga:transactions",
table.id = PID)
ga.query <- QueryBuilder(query.list)
# Extract the data and store it in a data-frame
tryCatch ( ga.dataCount <- nrow(GetReportData(ga.query, token)), error=function(e) flag<<-FALSE)
if (!flag) next
if (ga.dataCount < 10000)     {
# Extract the data and store it in a data-frame
ga.data <- GetReportData(ga.query, token)
} else {
# Extract the data and store it in a data-frame
ga.data <- GetReportData(ga.query, token, paginate_query=TRUE)
}
endtime=Sys.time()
ga.data$PID <- PID
print(PID)
ga.Consolidated <- rbind(ga.Consolidated, ga.data)
}
for(i in 1:length(Profile)){
flag <- TRUE
PID=Profile[i]
PID
ValidateToken(token)
query.list <- Init(start.date = as.character(St_date),
end.date = as.character(En_date),
dimensions = "ga:yearMonth, ga:week,ga:channelGrouping, ga:landingPagePath, ga:pageDepth,  ga:deviceCategory",
metrics = "ga:users, ga:sessions, ga:bounceRate, ga:pageviews, ga:avgSessionDuration, ga:totalEvents, ga:goalStartsAll, ga:goal1Starts, ga:goal3Starts, ga:goal6Starts",
start.index = 1,
segment = "ga:userType==New%20Visitor",
max.results = 10000,
#filters = "ga:userType%3D%3DNew Visitor",
#sort = "-ga:transactions",
table.id = PID)
ga.query <- QueryBuilder(query.list)
# Extract the data and store it in a data-frame
tryCatch ( ga.dataCount <- nrow(GetReportData(ga.query, token)), error=function(e) flag<<-FALSE)
if (!flag) next
if (ga.dataCount < 10000)     {
# Extract the data and store it in a data-frame
ga.data <- GetReportData(ga.query, token)
} else {
# Extract the data and store it in a data-frame
ga.data <- GetReportData(ga.query, token, paginate_query=TRUE)
}
endtime=Sys.time()
ga.data$PID <- PID
print(PID)
ga.Consolidated <- rbind(ga.Consolidated, ga.data)
}
for(i in 1:length(Profile)){
flag <- TRUE
PID=Profile[i]
PID
ValidateToken(token)
query.list <- Init(start.date = as.character(St_date),
end.date = as.character(En_date),
dimensions = "ga:yearMonth, ga:week,ga:channelGrouping, ga:landingPagePath, ga:pageDepth,  ga:deviceCategory",
metrics = "ga:users, ga:sessions, ga:bounceRate, ga:pageviews, ga:avgSessionDuration, ga:totalEvents, ga:goalStartsAll, ga:goal1Starts, ga:goal3Starts, ga:goal6Starts",
start.index = 1,
#segment = "ga:userType==New%20Visitor",
max.results = 10000,
#filters = "ga:userType==New%20Visitor",
#sort = "-ga:transactions",
table.id = PID)
ga.query <- QueryBuilder(query.list)
# Extract the data and store it in a data-frame
tryCatch ( ga.dataCount <- nrow(GetReportData(ga.query, token)), error=function(e) flag<<-FALSE)
if (!flag) next
if (ga.dataCount < 10000)     {
# Extract the data and store it in a data-frame
ga.data <- GetReportData(ga.query, token)
} else {
# Extract the data and store it in a data-frame
ga.data <- GetReportData(ga.query, token, paginate_query=TRUE)
}
endtime=Sys.time()
ga.data$PID <- PID
print(PID)
ga.Consolidated <- rbind(ga.Consolidated, ga.data)
}
for(i in 1:length(Profile)){
flag <- TRUE
PID=Profile[i]
PID
ValidateToken(token)
query.list <- Init(start.date = as.character(St_date),
end.date = as.character(En_date),
dimensions = "ga:yearMonth, ga:week,ga:channelGrouping, ga:landingPagePath, ga:pageDepth,  ga:deviceCategory",
metrics = "ga:users, ga:sessions, ga:bounceRate, ga:pageviews, ga:avgSessionDuration, ga:totalEvents, ga:goalStartsAll, ga:goal1Starts, ga:goal3Starts, ga:goal6Starts",
start.index = 1,
#segment = "ga:userType==New%20Visitor",
max.results = 10000,
filters = "ga:userType==New%20Visitor",
#sort = "-ga:transactions",
table.id = PID)
ga.query <- QueryBuilder(query.list)
# Extract the data and store it in a data-frame
tryCatch ( ga.dataCount <- nrow(GetReportData(ga.query, token)), error=function(e) flag<<-FALSE)
if (!flag) next
if (ga.dataCount < 10000)     {
# Extract the data and store it in a data-frame
ga.data <- GetReportData(ga.query, token)
} else {
# Extract the data and store it in a data-frame
ga.data <- GetReportData(ga.query, token, paginate_query=TRUE)
}
endtime=Sys.time()
ga.data$PID <- PID
print(PID)
ga.Consolidated <- rbind(ga.Consolidated, ga.data)
}
rm(list=ls(all=TRUE))
library("Rcpp")
library(XLConnect);
library(RGoogleAnalytics)
require(httpuv)
St_date='2017-01-01'
En_date='2017-06-05'
client.id <- "374177728354-lukeb737s4smlcsmdf52ninn90ce0t9d.apps.googleusercontent.com"
client.secret <- "EHgTYZ-ZYGEpPbj1gGAcTi0V"
token <- Auth(client.id,client.secret)
save(token,file="./token_file")
load("./token_file")
token
ValidateToken(token)
Profile <- c( "ga:97753012")
for(i in 1:length(Profile)){
flag <- TRUE
PID=Profile[i]
PID
ValidateToken(token)
query.list <- Init(start.date = as.character(St_date),
end.date = as.character(En_date),
dimensions = "ga:yearMonth, ga:week,ga:channelGrouping, ga:landingPagePath, ga:pageDepth,  ga:deviceCategory",
metrics = "ga:users, ga:sessions, ga:bounceRate, ga:pageviews, ga:avgSessionDuration, ga:totalEvents, ga:goalStartsAll, ga:goal1Starts, ga:goal3Starts, ga:goal6Starts",
start.index = 1,
#segment = "ga:userType==New%20Visitor",
max.results = 10000,
filters = "ga:userType==New%20Visitor",
#sort = "-ga:transactions",
table.id = PID)
ga.query <- QueryBuilder(query.list)
# Extract the data and store it in a data-frame
tryCatch ( ga.dataCount <- nrow(GetReportData(ga.query, token)), error=function(e) flag<<-FALSE)
if (!flag) next
if (ga.dataCount < 10000)     {
# Extract the data and store it in a data-frame
ga.data <- GetReportData(ga.query, token)
} else {
# Extract the data and store it in a data-frame
ga.data <- GetReportData(ga.query, token, paginate_query=TRUE)
}
endtime=Sys.time()
ga.data$PID <- PID
print(PID)
ga.Consolidated <- rbind(ga.Consolidated, ga.data)
}
library(openxlsx)
install.packages("openxlsx")
library(openxlsx)
library(plyr)
install.packages("plyr")
library(plyr)
install.packages("dplyr")
q()
library(dplyr)
install.packages("dplyr")
library(dplyr)
install.packages("library(RSiteCatalyst)")
library(library(RSiteCatalyst))
library(RSiteCatalyst)
library(RSiteCatalyst)
install.packages("RSiteCatalyst")
library("RSiteCatalyst")
install.packages("jsonlite")
library("jsonlite")
library(jsonlite)
library(jsonlite)
install.packages("jsonlite")
remove.packages("jsonlite")
install.packages("jsonlite")
library(jsonlite)
.libPaths()
install zoo
q()
library(swirl)
install.packages("swirl")
library(swirl)
swirl()
5+7
x <- 5+7
x
x-3
y <- x-3
y
z <- c(1.1,9,3.14)
?c
z
c(a,555,z)
c(z,555,z)
z *2 + 100
my_sqrt<- sqrt(z-1)
my_sqrt
my_div <- z/my_sqrt
my_div
c(1,2,3,4) + c(0,10)
c(1,2,3,4) + c(0,10,100)
c(1,2,3,4) + c(0,10,1000)
info()
z *2 + 1000
my_div
10
swirl()
dataset = read.csv('Social_Network_Ads.csv')
setwd("C:/Users/sainath.gaddam/Desktop/Machine Learning A-Z/Part 3 - Classification/Section 14 - Logistic Regression/Logistic_Regression")
dataset = read.csv('Social_Network_Ads.csv')
rm(list = ls())
setwd("C:/Users/sainath.gaddam/Desktop/Machine Learning A-Z/Part 3 - Classification/Section 14 - Logistic Regression/Logistic_Regression")
dataset = read.csv('Social_Network_Ads.csv')
View(dataset)
View(dataset)
View(dataset)
View(dataset)
dataset = dataset[3:5]
View(dataset)
View(dataset)
library(caTools)
install.packages('caTools')
library(caTools)
set.seed(123)
split = sample.split(dataset$Purchased, SplitRatio = 0.75)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
training_set[,1:2] = scale(training_set[,1:2])
test_set[,1:2] = scale(test_set[,1:2])
View(test_set)
View(test_set)
View(training_set)
View(training_set)
# Fitting Logistic Regression to the Training set
classifier = glm(formula = Purchased ~ .,
family = binomial,
data = training_set)
prob_pred = predict(classifier, type = 'response', newdata = test_set[-3])
y_pred = ifelse(prob_pred > 0.5, 1, 0)
cm = table(test_set[, 3], y_pred > 0.5)
cm
library(ElemStatLearn)
install.packages("ElemStatLearn")
library(ElemStatLearn)
set = training_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
prob_set = predict(classifier, type = 'response', newdata = grid_set)
y_grid = ifelse(prob_set > 0.5, 1, 0)
plot(set[, -3],
main = 'Logistic Regression (Training set)',
xlab = 'Age', ylab = 'Estimated Salary',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
# Visualising the Test set results
library(ElemStatLearn)
set = test_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
prob_set = predict(classifier, type = 'response', newdata = grid_set)
y_grid = ifelse(prob_set > 0.5, 1, 0)
plot(set[, -3],
main = 'Logistic Regression (Test set)',
xlab = 'Age', ylab = 'Estimated Salary',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
# Visualising the Test set results
library(ElemStatLearn)
set = test_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
prob_set = predict(classifier, type = 'response', newdata = grid_set)
y_grid = ifelse(prob_set > 0.5, 1, 0)
plot(set[, -3],
main = 'Logistic Regression (Test set)',
xlab = 'Age', ylab = 'Estimated Salary',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
setwd("C:/Users/sainath.gaddam/Desktop/Machine Learning A-Z/Part 3 - Classification/Section 15 - K-Nearest Neighbors (K-NN)/K_Nearest_Neighbors")
rm(list = ls())
# Classification template
# Importing the dataset
dataset = read.csv('Social_Network_Ads.csv')
dataset = dataset[3:5]
# Encoding the target feature as factor
dataset$Purchased = factor(dataset$Purchased, levels = c(0, 1))
# Splitting the dataset into the Training set and Test set
# install.packages('caTools')
library(caTools)
set.seed(123)
split = sample.split(dataset$Purchased, SplitRatio = 0.75)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
# Feature Scaling
training_set[-3] = scale(training_set[-3])
test_set[-3] = scale(test_set[-3])
View(dataset)
View(dataset)
View(test_set)
View(training_set)
View(dataset)
library(class)
y_pred = knn(training_set[,-3]
, test= test_set[,-3],
cl = training_set[,3],
k = 5)
y_pred
cm = table(test_set[, 3], y_pred)
cm
library(ElemStatLearn)
set = training_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
y_grid = y_pred = knn(training_set[,-3]
, test= grid_set,
cl = training_set[,3],
k = 5)
plot(set[, -3],
main = 'Classifier (Training set)',
xlab = 'Age', ylab = 'Estimated Salary',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
