Energy <- jsonlite::fromJSON(URL)
sankeyNetwork(Links = Energy$links, Nodes = Energy$nodes, Source = "source",
Target = "target", Value = "value", NodeID = "name",
units = "TWh", fontSize = 12, nodeWidth = 30)
sankeyNetwork(Links = Energy$links, Nodes = Energy$nodes, Source = "source", Target = "target", Value = "value", NodeID = "name", units = "TWh", fontSize = 12, nodeWidth = 30)
library(d3Network)
sankeyNetwork(Links = Energy$links, Nodes = Energy$nodes, Source = "source", Target = "target", Value = "value", NodeID = "name", units = "TWh", fontSize = 12, nodeWidth = 30)
library(networkD3)
sankeyNetwork(Links = Energy$links, Nodes = Energy$nodes, Source = "source", Target = "target", Value = "value", NodeID = "name", units = "TWh", fontSize = 12, nodeWidth = 30)
Energy$links[:2]
Energy$links[,2]
Energy$nodes
URL
URL = file:///C:/Users/sainath.gaddam/Desktop/Pranab/data.json
URL = "file:///C:/Users/sainath.gaddam/Desktop/Pranab/data.json"
Energy <- jsonlite::fromJSON(URL)
install.packages("RJSONIO")
library("RJSONIO")
l <- fromJSON({"nodes":[
{"name":"Agricultural 'waste'"},
{"name":"Bio-conversion"}
],
"links":[
{"source":0,"target":1,"value":124.729},
{"source":1,"target":2,"value":0.597}
]})
rm(list = ls())
#Multi-page pathing
library("d3Network")
library("RSiteCatalyst")
#### Authentication
#SCAuth("name", "secret")
SCAuth("p.singh:FCA EMEA", "77491d458a82880b097ad54b283acbd6")
#### Get All Possible Paths with ("::anything::", "::anything::")
pathpattern <- c("::anything::", "::anything::")
next_page <- QueuePathing("fcae.fiat.belux",
"2016-01-01",
"2016-08-31",
metric="pageviews",
element="page",
pathpattern,
top = 50000)
#Optional step: Cleaning my pagename URLs to remove to domain for clarity
next_page$step.1 <- sub("www.fiat.be/fr/","",
next_page$step.1, ignore.case = TRUE)
next_page$step.2 <- sub("www.fiat.be/fr/","",
next_page$step.2, ignore.case = TRUE)
#Filter out Entered Site and duplicate rows, >120 for chart legibility
links <- subset(next_page, count >= 120 & step.1 != "Entered Site")
#Get unique values of page name to create nodes df
#Create an index value, starting at 0
nodes <- as.data.frame(unique(c(links$step.1, links$step.2)))
names(nodes) <- "name"
nodes$nodevalue <- as.numeric(row.names(nodes)) - 1
#Convert string to numeric nodeid
links <- merge(links, nodes, by.x="step.1", by.y="name")
names(links) <- c("step.1", "step.2", "value", "segment.id", "segment.name", "source")
links <- merge(links, nodes, by.x="step.2", by.y="name")
names(links) <- c("step.2", "step.1", "value", "segment.id", "segment.name","source", "target")
#Create next page Sankey chart
d3output = "all.html"
d3Sankey(Links = links, Nodes = nodes, Source = "source",
Target = "target", Value = "value", NodeID = "name",
fontsize = 12, nodeWidth = 50, file = d3output, width = 750, height = 700)
rm(list = ls())
str(state.region)
head(state.region)
state.region
names(state.region)
str(state.region)
table(state.region)
barplot(table(state.region))
barplot(table(state.region), cex.names = 0.5)
barplot(prop.table(table(state.region)), cex.names = 0.5)
barplot(table(state.region), cex.names = 0.5)
barplot(prop.table(table(state.region)), cex.names = 0.5)
barplot(table(state.region), cex.names = 0.5)
barplot(prop.table(table(state.region)), cex.names = 0.5)
?par
x <- 5:9
x
y <- (x < 7)
y
x <- c(3,7,NA)
y <- c(NA,1,a)
y <- c(NA,1,2)
x+y
sum(x)
sum(x, na.rm = TRUE)
is.na(x)
x[is.na(x)]
x[!is.na(x)]
version
mod <- lm(dist ~ speed, data = cars)
mean(mod$residuals)
par(mfrow = c(2,2))
mod_1 <- lm(mpg ~ disp, data = mtcars)
plot(mod_1)
library(swirl)
swirl()
swirl()
library(car)
mod2 <- lm(mpg ~ ., data = mtcars)
vif(mod2)
summary(mod2)
library(carrplot)
install.packages(carrplot)
install.packages("corrplot")
library(carrplot)
library(corrplot)
cor(mtcars[,-1])
corrplot(cor(mtcars[,-1]))
mod <- lm(mpg ~ cyl + gear, data = mtcars)
summary(mod)
vif(mod = )
vif(mod)
par(mfrow=c(2,2))
mod <- lm(dist ~ speed, data = cars)
plot(mod)
install.packages("gvlma")
library(gvlma)
gvlma::gvlma(mod)
mod <- lm(dist ~ speed, data=cars[-c(23, 35, 49), ])
gvlma::gvlma(mod)
rm(list=ls(all=TRUE)) #clear all objects in workspace
install.packages("RGoogleAnalytics")
install.packages("httpuv")
install.packages("Rcpp")
install.packages("RCurl")
library("Rcpp")
library(XLConnect);
library(RGoogleAnalytics)
require(httpuv)
St_date='2017-01-01'
En_date='2017-06-05'
client.id <- "374177728354-lukeb737s4smlcsmdf52ninn90ce0t9d.apps.googleusercontent.com"
client.secret <- "EHgTYZ-ZYGEpPbj1gGAcTi0V"
token <- Auth(client.id,client.secret)
token <- Auth(client.id,client.secret)
token <- Auth(client.id,client.secret)
token <- Auth(client.id,client.secret)
rm(list=ls(all=TRUE)) #clear all objects in workspace
library("Rcpp")
library(XLConnect);
library(RGoogleAnalytics)
require(httpuv)
St_date='2017-01-01'
En_date='2017-06-05'
client.id <- "374177728354-lukeb737s4smlcsmdf52ninn90ce0t9d.apps.googleusercontent.com"
client.secret <- "EHgTYZ-ZYGEpPbj1gGAcTi0V"
token <- Auth(client.id,client.secret)
save(token,file="./token_file")
load("./token_file")
token
ValidateToken(token)
Profile <- c( "ga:97753012")
starttime=Sys.time()
query.list <- Init(start.date = as.character(St_date),
end.date = as.character(En_date),
dimensions = "ga:yearMonth, ga:week,ga:channelGrouping, ga:landingPagePath, ga:pageDepth,  ga:deviceCategory",
metrics = "ga:users, ga:sessions, ga:bounceRate, ga:pageviews, ga:avgSessionDuration, ga:totalEvents, ga:goalStartsAll, ga:goal1Starts, ga:goal3Starts, ga:goal6Starts",
start.index = 1,
max.results = 10000,
filters = c("ga:userType==New Visitor"),
#sort = "-ga:transactions",
table.id = PID)
ga.query <- QueryBuilder(query.list)
query.list <- Init(start.date = as.character(St_date),
end.date = as.character(En_date),
dimensions = "ga:yearMonth, ga:week,ga:channelGrouping, ga:landingPagePath, ga:pageDepth,  ga:deviceCategory",
metrics = "ga:users, ga:sessions, ga:bounceRate, ga:pageviews, ga:avgSessionDuration, ga:totalEvents, ga:goalStartsAll, ga:goal1Starts, ga:goal3Starts, ga:goal6Starts",
start.index = 1,
max.results = 10000,
filters = c("ga:userType==New Visitor"),
#sort = "-ga:transactions",
table.id = PID)
for(i in 1:length(Profile)){
flag <- TRUE
PID=Profile[i]
PID
ValidateToken(token)
query.list <- Init(start.date = as.character(St_date),
end.date = as.character(En_date),
dimensions = "ga:yearMonth, ga:week,ga:channelGrouping, ga:landingPagePath, ga:pageDepth,  ga:deviceCategory",
metrics = "ga:users, ga:sessions, ga:bounceRate, ga:pageviews, ga:avgSessionDuration, ga:totalEvents, ga:goalStartsAll, ga:goal1Starts, ga:goal3Starts, ga:goal6Starts",
start.index = 1,
max.results = 10000,
filters = c("ga:userType==New Visitor"),
#sort = "-ga:transactions",
table.id = PID)
ga.query <- QueryBuilder(query.list)
# Extract the data and store it in a data-frame
tryCatch ( ga.dataCount <- nrow(GetReportData(ga.query, token)), error=function(e) flag<<-FALSE)
if (!flag) next
if (ga.dataCount < 10000)     {
# Extract the data and store it in a data-frame
ga.data <- GetReportData(ga.query, token)
} else {
# Extract the data and store it in a data-frame
ga.data <- GetReportData(ga.query, token, paginate_query=TRUE)
}
endtime=Sys.time()
ga.data$PID <- PID
print(PID)
ga.Consolidated <- rbind(ga.Consolidated, ga.data)
}
for(i in 1:length(Profile)){
flag <- TRUE
PID=Profile[i]
PID
ValidateToken(token)
query.list <- Init(start.date = as.character(St_date),
end.date = as.character(En_date),
dimensions = "ga:yearMonth, ga:week,ga:channelGrouping, ga:landingPagePath, ga:pageDepth,  ga:deviceCategory",
metrics = "ga:users, ga:sessions, ga:bounceRate, ga:pageviews, ga:avgSessionDuration, ga:totalEvents, ga:goalStartsAll, ga:goal1Starts, ga:goal3Starts, ga:goal6Starts",
start.index = 1,
max.results = 10000,
#filters = c("ga:userType==New Visitor"),
#sort = "-ga:transactions",
table.id = PID)
ga.query <- QueryBuilder(query.list)
# Extract the data and store it in a data-frame
tryCatch ( ga.dataCount <- nrow(GetReportData(ga.query, token)), error=function(e) flag<<-FALSE)
if (!flag) next
if (ga.dataCount < 10000)     {
# Extract the data and store it in a data-frame
ga.data <- GetReportData(ga.query, token)
} else {
# Extract the data and store it in a data-frame
ga.data <- GetReportData(ga.query, token, paginate_query=TRUE)
}
endtime=Sys.time()
ga.data$PID <- PID
print(PID)
ga.Consolidated <- rbind(ga.Consolidated, ga.data)
}
for(i in 1:length(Profile)){
flag <- TRUE
PID=Profile[i]
PID
ValidateToken(token)
query.list <- Init(start.date = as.character(St_date),
end.date = as.character(En_date),
dimensions = "ga:yearMonth, ga:week,ga:channelGrouping, ga:landingPagePath, ga:pageDepth,  ga:deviceCategory",
metrics = "ga:users, ga:sessions, ga:bounceRate, ga:pageviews, ga:avgSessionDuration, ga:totalEvents, ga:goalStartsAll, ga:goal1Starts, ga:goal3Starts, ga:goal6Starts",
start.index = 1,
max.results = 10000,
filters = "ga:userType%3D%3DNew Visitor",
#sort = "-ga:transactions",
table.id = PID)
ga.query <- QueryBuilder(query.list)
# Extract the data and store it in a data-frame
tryCatch ( ga.dataCount <- nrow(GetReportData(ga.query, token)), error=function(e) flag<<-FALSE)
if (!flag) next
if (ga.dataCount < 10000)     {
# Extract the data and store it in a data-frame
ga.data <- GetReportData(ga.query, token)
} else {
# Extract the data and store it in a data-frame
ga.data <- GetReportData(ga.query, token, paginate_query=TRUE)
}
endtime=Sys.time()
ga.data$PID <- PID
print(PID)
ga.Consolidated <- rbind(ga.Consolidated, ga.data)
}
for(i in 1:length(Profile)){
flag <- TRUE
PID=Profile[i]
PID
ValidateToken(token)
query.list <- Init(start.date = as.character(St_date),
end.date = as.character(En_date),
dimensions = "ga:yearMonth, ga:week,ga:channelGrouping, ga:landingPagePath, ga:pageDepth,  ga:deviceCategory",
metrics = "ga:users, ga:sessions, ga:bounceRate, ga:pageviews, ga:avgSessionDuration, ga:totalEvents, ga:goalStartsAll, ga:goal1Starts, ga:goal3Starts, ga:goal6Starts",
start.index = 1,
segment = "ga:userType==New%20Visitor",
max.results = 10000,
#filters = "ga:userType%3D%3DNew Visitor",
#sort = "-ga:transactions",
table.id = PID)
ga.query <- QueryBuilder(query.list)
# Extract the data and store it in a data-frame
tryCatch ( ga.dataCount <- nrow(GetReportData(ga.query, token)), error=function(e) flag<<-FALSE)
if (!flag) next
if (ga.dataCount < 10000)     {
# Extract the data and store it in a data-frame
ga.data <- GetReportData(ga.query, token)
} else {
# Extract the data and store it in a data-frame
ga.data <- GetReportData(ga.query, token, paginate_query=TRUE)
}
endtime=Sys.time()
ga.data$PID <- PID
print(PID)
ga.Consolidated <- rbind(ga.Consolidated, ga.data)
}
for(i in 1:length(Profile)){
flag <- TRUE
PID=Profile[i]
PID
ValidateToken(token)
query.list <- Init(start.date = as.character(St_date),
end.date = as.character(En_date),
dimensions = "ga:yearMonth, ga:week,ga:channelGrouping, ga:landingPagePath, ga:pageDepth,  ga:deviceCategory",
metrics = "ga:users, ga:sessions, ga:bounceRate, ga:pageviews, ga:avgSessionDuration, ga:totalEvents, ga:goalStartsAll, ga:goal1Starts, ga:goal3Starts, ga:goal6Starts",
start.index = 1,
#segment = "ga:userType==New%20Visitor",
max.results = 10000,
#filters = "ga:userType==New%20Visitor",
#sort = "-ga:transactions",
table.id = PID)
ga.query <- QueryBuilder(query.list)
# Extract the data and store it in a data-frame
tryCatch ( ga.dataCount <- nrow(GetReportData(ga.query, token)), error=function(e) flag<<-FALSE)
if (!flag) next
if (ga.dataCount < 10000)     {
# Extract the data and store it in a data-frame
ga.data <- GetReportData(ga.query, token)
} else {
# Extract the data and store it in a data-frame
ga.data <- GetReportData(ga.query, token, paginate_query=TRUE)
}
endtime=Sys.time()
ga.data$PID <- PID
print(PID)
ga.Consolidated <- rbind(ga.Consolidated, ga.data)
}
for(i in 1:length(Profile)){
flag <- TRUE
PID=Profile[i]
PID
ValidateToken(token)
query.list <- Init(start.date = as.character(St_date),
end.date = as.character(En_date),
dimensions = "ga:yearMonth, ga:week,ga:channelGrouping, ga:landingPagePath, ga:pageDepth,  ga:deviceCategory",
metrics = "ga:users, ga:sessions, ga:bounceRate, ga:pageviews, ga:avgSessionDuration, ga:totalEvents, ga:goalStartsAll, ga:goal1Starts, ga:goal3Starts, ga:goal6Starts",
start.index = 1,
#segment = "ga:userType==New%20Visitor",
max.results = 10000,
filters = "ga:userType==New%20Visitor",
#sort = "-ga:transactions",
table.id = PID)
ga.query <- QueryBuilder(query.list)
# Extract the data and store it in a data-frame
tryCatch ( ga.dataCount <- nrow(GetReportData(ga.query, token)), error=function(e) flag<<-FALSE)
if (!flag) next
if (ga.dataCount < 10000)     {
# Extract the data and store it in a data-frame
ga.data <- GetReportData(ga.query, token)
} else {
# Extract the data and store it in a data-frame
ga.data <- GetReportData(ga.query, token, paginate_query=TRUE)
}
endtime=Sys.time()
ga.data$PID <- PID
print(PID)
ga.Consolidated <- rbind(ga.Consolidated, ga.data)
}
rm(list=ls(all=TRUE))
library("Rcpp")
library(XLConnect);
library(RGoogleAnalytics)
require(httpuv)
St_date='2017-01-01'
En_date='2017-06-05'
client.id <- "374177728354-lukeb737s4smlcsmdf52ninn90ce0t9d.apps.googleusercontent.com"
client.secret <- "EHgTYZ-ZYGEpPbj1gGAcTi0V"
token <- Auth(client.id,client.secret)
save(token,file="./token_file")
load("./token_file")
token
ValidateToken(token)
Profile <- c( "ga:97753012")
for(i in 1:length(Profile)){
flag <- TRUE
PID=Profile[i]
PID
ValidateToken(token)
query.list <- Init(start.date = as.character(St_date),
end.date = as.character(En_date),
dimensions = "ga:yearMonth, ga:week,ga:channelGrouping, ga:landingPagePath, ga:pageDepth,  ga:deviceCategory",
metrics = "ga:users, ga:sessions, ga:bounceRate, ga:pageviews, ga:avgSessionDuration, ga:totalEvents, ga:goalStartsAll, ga:goal1Starts, ga:goal3Starts, ga:goal6Starts",
start.index = 1,
#segment = "ga:userType==New%20Visitor",
max.results = 10000,
filters = "ga:userType==New%20Visitor",
#sort = "-ga:transactions",
table.id = PID)
ga.query <- QueryBuilder(query.list)
# Extract the data and store it in a data-frame
tryCatch ( ga.dataCount <- nrow(GetReportData(ga.query, token)), error=function(e) flag<<-FALSE)
if (!flag) next
if (ga.dataCount < 10000)     {
# Extract the data and store it in a data-frame
ga.data <- GetReportData(ga.query, token)
} else {
# Extract the data and store it in a data-frame
ga.data <- GetReportData(ga.query, token, paginate_query=TRUE)
}
endtime=Sys.time()
ga.data$PID <- PID
print(PID)
ga.Consolidated <- rbind(ga.Consolidated, ga.data)
}
library(openxlsx)
install.packages("openxlsx")
library(openxlsx)
library(plyr)
install.packages("plyr")
library(plyr)
install.packages("dplyr")
q()
library(dplyr)
install.packages("dplyr")
library(dplyr)
install.packages("library(RSiteCatalyst)")
library(library(RSiteCatalyst))
library(RSiteCatalyst)
library(RSiteCatalyst)
install.packages("RSiteCatalyst")
library("RSiteCatalyst")
install.packages("jsonlite")
library("jsonlite")
library(jsonlite)
library(jsonlite)
install.packages("jsonlite")
remove.packages("jsonlite")
install.packages("jsonlite")
library(jsonlite)
.libPaths()
install zoo
q()
library(swirl)
install.packages("swirl")
library(swirl)
swirl()
5+7
x <- 5+7
x
x-3
y <- x-3
y
z <- c(1.1,9,3.14)
?c
z
c(a,555,z)
c(z,555,z)
z *2 + 100
my_sqrt<- sqrt(z-1)
my_sqrt
my_div <- z/my_sqrt
my_div
c(1,2,3,4) + c(0,10)
c(1,2,3,4) + c(0,10,100)
c(1,2,3,4) + c(0,10,1000)
info()
z *2 + 1000
my_div
10
swirl()
rm(list = ls())
library(e1071)
install.packages('e1071')
library(e1071)
library(e1071)
library(e1071)
install.packages('e1071')
library(e1071)
dataset = read.csv('Social_Network_Ads.csv')
dataset = dataset[3:5]
setwd("C:/Users/sainath.gaddam/Desktop/Machine Learning A-Z/Part 3 - Classification/Section 16 - Support Vector Machine (SVM)")
# Support Vector Machine (SVM)
# Importing the dataset
dataset = read.csv('Social_Network_Ads.csv')
dataset = dataset[3:5]
dataset$Purchased = factor(dataset$Purchased, levels = c(0, 1))
# Splitting the dataset into the Training set and Test set
# install.packages('caTools')
library(caTools)
set.seed(123)
split = sample.split(dataset$Purchased, SplitRatio = 0.75)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
# Feature Scaling
training_set[-3] = scale(training_set[-3])
test_set[-3] = scale(test_set[-3])
library(e1071)
classifier = svm(formula = Purchased ~ .,
data = training_set,
type = 'C-classification',
kernel = 'linear')
# Predicting the Test set results
y_pred = predict(classifier, newdata = test_set[-3])
# Making the Confusion Matrix
cm = table(test_set[, 3], y_pred)
cm
# Visualising the Training set results
library(ElemStatLearn)
set = training_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
y_grid = predict(classifier, newdata = grid_set)
plot(set[, -3],
main = 'SVM (Training set)',
xlab = 'Age', ylab = 'Estimated Salary',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
